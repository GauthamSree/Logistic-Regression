{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression using Pytorch\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 & 1 - Identify will the customers make a specific transaction in the future or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(['0', '1'], height= np.array(df['target'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum() == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>5.6669</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>6.0019</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>6.1629</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>8.7542</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>9.3688</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1    var_2   var_3    var_4    var_5   var_6    var_7  \\\n",
       "0        8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187  18.6266   \n",
       "1       11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208  16.5338   \n",
       "2        8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427  14.6155   \n",
       "3       11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428  14.9250   \n",
       "4        9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405  19.2514   \n",
       "...         ...     ...      ...     ...      ...      ...     ...      ...   \n",
       "199995  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709  15.1516   \n",
       "199996   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802  21.5940   \n",
       "199997  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555  21.5571   \n",
       "199998   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479  17.0152   \n",
       "199999  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839  15.2058   \n",
       "\n",
       "         var_8   var_9  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0      -4.9200  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1       3.1468  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2      -4.9193  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3      -5.8609  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4       6.2654  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995 -0.6209  5.6669  ...   6.1415  13.2305   3.9901   0.9388  18.0249   \n",
       "199996 -3.6797  6.0019  ...   4.9611   4.6549   0.6998   1.8341  22.2717   \n",
       "199997  0.1202  6.1629  ...   4.0651   5.4414   3.1032   4.8793  23.5311   \n",
       "199998 -2.1926  8.7542  ...   2.6840   8.6587   2.7337  11.1178  20.4158   \n",
       "199999 -0.4541  9.3688  ...   8.9842   1.6893   0.1276   0.3766  15.2101   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0       -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1        2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2        3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the dataset for neutral network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, skip_flds=None):\n",
    "    for col in df.columns:\n",
    "        if col == skip_flds:\n",
    "            continue\n",
    "        else:\n",
    "            mean, std = df[col].mean(), df[col].std()\n",
    "            df[col] = (df[col] - mean)/(1e-7 + std)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize(df,skip_flds='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>2.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>-4.955295e-14</td>\n",
       "      <td>-1.848151e-15</td>\n",
       "      <td>-2.763518e-14</td>\n",
       "      <td>-8.757870e-15</td>\n",
       "      <td>-7.285757e-14</td>\n",
       "      <td>-4.036039e-15</td>\n",
       "      <td>4.808608e-14</td>\n",
       "      <td>-3.160777e-14</td>\n",
       "      <td>1.141323e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>7.719343e-15</td>\n",
       "      <td>-1.449932e-14</td>\n",
       "      <td>-2.060941e-14</td>\n",
       "      <td>-5.310298e-15</td>\n",
       "      <td>2.591193e-15</td>\n",
       "      <td>3.540945e-15</td>\n",
       "      <td>-3.412070e-15</td>\n",
       "      <td>1.079554e-14</td>\n",
       "      <td>-1.733072e-13</td>\n",
       "      <td>-1.612577e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.378731e+00</td>\n",
       "      <td>-3.312502e+00</td>\n",
       "      <td>-3.255750e+00</td>\n",
       "      <td>-3.345894e+00</td>\n",
       "      <td>-3.698694e+00</td>\n",
       "      <td>-3.496929e+00</td>\n",
       "      <td>-3.532913e+00</td>\n",
       "      <td>-3.275571e+00</td>\n",
       "      <td>-3.237578e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.800008e+00</td>\n",
       "      <td>-3.350710e+00</td>\n",
       "      <td>-3.884097e+00</td>\n",
       "      <td>-3.786337e+00</td>\n",
       "      <td>-2.966157e+00</td>\n",
       "      <td>-3.581230e+00</td>\n",
       "      <td>-3.027469e+00</td>\n",
       "      <td>-3.198216e+00</td>\n",
       "      <td>-3.178875e+00</td>\n",
       "      <td>-3.403546e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.322457e-01</td>\n",
       "      <td>-7.684862e-01</td>\n",
       "      <td>-7.545614e-01</td>\n",
       "      <td>-7.548768e-01</td>\n",
       "      <td>-7.363204e-01</td>\n",
       "      <td>-7.802142e-01</td>\n",
       "      <td>-7.399530e-01</td>\n",
       "      <td>-7.612616e-01</td>\n",
       "      <td>-7.807524e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.222196e-01</td>\n",
       "      <td>-7.544834e-01</td>\n",
       "      <td>-7.021424e-01</td>\n",
       "      <td>-6.881645e-01</td>\n",
       "      <td>-7.540230e-01</td>\n",
       "      <td>-7.196246e-01</td>\n",
       "      <td>-7.792395e-01</td>\n",
       "      <td>-7.110889e-01</td>\n",
       "      <td>-6.778669e-01</td>\n",
       "      <td>-7.551185e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.104002e-02</td>\n",
       "      <td>4.832463e-03</td>\n",
       "      <td>-5.119169e-02</td>\n",
       "      <td>1.393363e-02</td>\n",
       "      <td>1.843130e-02</td>\n",
       "      <td>2.952558e-02</td>\n",
       "      <td>-2.751959e-02</td>\n",
       "      <td>-2.605264e-02</td>\n",
       "      <td>3.286834e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.763225e-03</td>\n",
       "      <td>-2.998683e-02</td>\n",
       "      <td>-1.795056e-02</td>\n",
       "      <td>1.617631e-02</td>\n",
       "      <td>-1.142977e-02</td>\n",
       "      <td>-2.141609e-02</td>\n",
       "      <td>1.935416e-02</td>\n",
       "      <td>-2.165487e-02</td>\n",
       "      <td>2.103318e-02</td>\n",
       "      <td>4.857120e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.836352e-01</td>\n",
       "      <td>7.373368e-01</td>\n",
       "      <td>6.821584e-01</td>\n",
       "      <td>7.475929e-01</td>\n",
       "      <td>7.287016e-01</td>\n",
       "      <td>7.617848e-01</td>\n",
       "      <td>6.854907e-01</td>\n",
       "      <td>7.480964e-01</td>\n",
       "      <td>7.962886e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.955734e-01</td>\n",
       "      <td>6.860503e-01</td>\n",
       "      <td>6.910482e-01</td>\n",
       "      <td>7.199410e-01</td>\n",
       "      <td>7.663849e-01</td>\n",
       "      <td>6.798007e-01</td>\n",
       "      <td>7.798133e-01</td>\n",
       "      <td>7.434064e-01</td>\n",
       "      <td>7.286763e-01</td>\n",
       "      <td>7.820775e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.169383e+00</td>\n",
       "      <td>2.964022e+00</td>\n",
       "      <td>3.270789e+00</td>\n",
       "      <td>3.128131e+00</td>\n",
       "      <td>3.445811e+00</td>\n",
       "      <td>2.838123e+00</td>\n",
       "      <td>3.506491e+00</td>\n",
       "      <td>3.260885e+00</td>\n",
       "      <td>2.960763e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.334807e+00</td>\n",
       "      <td>3.068891e+00</td>\n",
       "      <td>4.379370e+00</td>\n",
       "      <td>3.744968e+00</td>\n",
       "      <td>3.168900e+00</td>\n",
       "      <td>3.088760e+00</td>\n",
       "      <td>2.936758e+00</td>\n",
       "      <td>3.355205e+00</td>\n",
       "      <td>3.390423e+00</td>\n",
       "      <td>3.049166e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target         var_0         var_1         var_2         var_3  \\\n",
       "count  200000.000000  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
       "mean        0.100490 -4.955295e-14 -1.848151e-15 -2.763518e-14 -8.757870e-15   \n",
       "std         0.300653  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min         0.000000 -3.378731e+00 -3.312502e+00 -3.255750e+00 -3.345894e+00   \n",
       "25%         0.000000 -7.322457e-01 -7.684862e-01 -7.545614e-01 -7.548768e-01   \n",
       "50%         0.000000 -5.104002e-02  4.832463e-03 -5.119169e-02  1.393363e-02   \n",
       "75%         0.000000  6.836352e-01  7.373368e-01  6.821584e-01  7.475929e-01   \n",
       "max         1.000000  3.169383e+00  2.964022e+00  3.270789e+00  3.128131e+00   \n",
       "\n",
       "              var_4         var_5         var_6         var_7         var_8  \\\n",
       "count  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
       "mean  -7.285757e-14 -4.036039e-15  4.808608e-14 -3.160777e-14  1.141323e-15   \n",
       "std    9.999999e-01  1.000000e+00  9.999999e-01  1.000000e+00  1.000000e+00   \n",
       "min   -3.698694e+00 -3.496929e+00 -3.532913e+00 -3.275571e+00 -3.237578e+00   \n",
       "25%   -7.363204e-01 -7.802142e-01 -7.399530e-01 -7.612616e-01 -7.807524e-01   \n",
       "50%    1.843130e-02  2.952558e-02 -2.751959e-02 -2.605264e-02  3.286834e-02   \n",
       "75%    7.287016e-01  7.617848e-01  6.854907e-01  7.480964e-01  7.962886e-01   \n",
       "max    3.445811e+00  2.838123e+00  3.506491e+00  3.260885e+00  2.960763e+00   \n",
       "\n",
       "       ...       var_190       var_191       var_192       var_193  \\\n",
       "count  ...  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
       "mean   ...  7.719343e-15 -1.449932e-14 -2.060941e-14 -5.310298e-15   \n",
       "std    ...  1.000000e+00  1.000000e+00  9.999999e-01  1.000000e+00   \n",
       "min    ... -3.800008e+00 -3.350710e+00 -3.884097e+00 -3.786337e+00   \n",
       "25%    ... -7.222196e-01 -7.544834e-01 -7.021424e-01 -6.881645e-01   \n",
       "50%    ... -6.763225e-03 -2.998683e-02 -1.795056e-02  1.617631e-02   \n",
       "75%    ...  6.955734e-01  6.860503e-01  6.910482e-01  7.199410e-01   \n",
       "max    ...  3.334807e+00  3.068891e+00  4.379370e+00  3.744968e+00   \n",
       "\n",
       "            var_194       var_195       var_196       var_197       var_198  \\\n",
       "count  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05  2.000000e+05   \n",
       "mean   2.591193e-15  3.540945e-15 -3.412070e-15  1.079554e-14 -1.733072e-13   \n",
       "std    1.000000e+00  9.999999e-01  1.000000e+00  9.999999e-01  1.000000e+00   \n",
       "min   -2.966157e+00 -3.581230e+00 -3.027469e+00 -3.198216e+00 -3.178875e+00   \n",
       "25%   -7.540230e-01 -7.196246e-01 -7.792395e-01 -7.110889e-01 -6.778669e-01   \n",
       "50%   -1.142977e-02 -2.141609e-02  1.935416e-02 -2.165487e-02  2.103318e-02   \n",
       "75%    7.663849e-01  6.798007e-01  7.798133e-01  7.434064e-01  7.286763e-01   \n",
       "max    3.168900e+00  3.088760e+00  2.936758e+00  3.355205e+00  3.390423e+00   \n",
       "\n",
       "            var_199  \n",
       "count  2.000000e+05  \n",
       "mean  -1.612577e-16  \n",
       "std    1.000000e+00  \n",
       "min   -3.403546e+00  \n",
       "25%   -7.551185e-01  \n",
       "50%    4.857120e-02  \n",
       "75%    7.820775e-01  \n",
       "max    3.049166e+00  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.permutation(len(df))\n",
    "train_idxs, val_idxs = idxs[:160000], idxs[160000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[train_idxs]\n",
    "valid_df = df.iloc[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143954\n",
       "1     16046\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35948\n",
       "1     4052\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "axs[0].bar(['0', '1'], height= np.array(train_df['target'].value_counts()))\n",
    "axs[0].set_title('Train')\n",
    "axs[1].bar(['0', '1'], height= np.array(valid_df['target'].value_counts()))\n",
    "axs[1].set_title('Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('processed/train.csv', index=False)\n",
    "valid_df.to_csv('processed/valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "* creating dataset class\n",
    "* WeightedRandomSampling train dataset for balanced training\n",
    "* creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transactionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dep_var=None, valid=False):\n",
    "        if valid:\n",
    "            self.df = pd.read_csv('processed/valid.csv')\n",
    "        else:\n",
    "            self.df = pd.read_csv('processed/train.csv')\n",
    "        self.dep_var = dep_var\n",
    "        self.classes = self.df[self.dep_var].unique()\n",
    "        self.X = torch.tensor(self.df.drop(self.dep_var, axis=1).values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.df[self.dep_var].values, dtype=torch.float32)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transactionDataset(dep_var='target')\n",
    "valid = transactionDataset(dep_var='target', valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Random Sampler\n",
    "Since we have Imbalanced dataset, we need to Oversample the dataset while taking each batch for training.\n",
    "<br>We are doing WeightedRandomSampling on train dataset.\n",
    "\n",
    "WeightedRandomSampler is used to ensure that each batch sees a proportional number of all classes.\n",
    "1. Get all the target labels.\n",
    "2. Get the counts of each target labels.\n",
    "3. Get the weights. Weights are the inversely reciprocal of the number of items per class.\n",
    "    - weights = (1/counts)[target_labels]\n",
    "4. Obtain total length of oversample.\n",
    "    - total_len_oversample = no_of_classes * max(counts)\n",
    "5. Provide weights and total_len_oversample to the WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "train_labels = train.df['target'].values\n",
    "_ , counts = np.unique(train_labels,return_counts=True)\n",
    "weights = torch.DoubleTensor((1/counts)[train_labels])\n",
    "total_len_oversample = int(train.df['target'].nunique()*np.max(counts))\n",
    "sampler = WeightedRandomSampler(weights, total_len_oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = DataLoader(train, batch_size=64, sampler=sampler)\n",
    "validset = DataLoader(valid, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "* creating model class \n",
    "* defining the training loop\n",
    "* Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_input, n_out):\n",
    "        super(LogisticRegressionNN, self).__init__()\n",
    "        self.linear = nn.Linear(n_input, n_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "model = LogisticRegressionNN(200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_learner():\n",
    "    def fit(self, model, trainset, validset, lr, epochs):\n",
    "        \n",
    "        train_loss = []\n",
    "        valid_loss = []\n",
    "        roc_auc = []\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for X, y in trainset:\n",
    "                ## Forward pass and loss \n",
    "                output = model(X)\n",
    "                loss = criterion(output, y.view(-1, 1))\n",
    "                ## backward pass (backpropagation)\n",
    "                loss.backward()\n",
    "                ## Update the weights and zero_grad\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            ## append loss\n",
    "            train_loss.append(loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                val_loss = []\n",
    "                for X_val, y_val in validset:\n",
    "                    preds = model(X_val)\n",
    "                    loss = criterion(preds, y_val.view(-1, 1))\n",
    "                    val_loss.append(loss)\n",
    "\n",
    "                valid_loss.append(torch.stack(val_loss).mean())\n",
    "            print(f'Epoch : {epoch} | Train Loss: {train_loss[epoch]:.4f} | Validation Loss: {valid_loss[epoch]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 | Train Loss: 0.5138 | Validation Loss: 0.5910\n",
      "Epoch : 1 | Train Loss: 0.3592 | Validation Loss: 0.5391\n",
      "Epoch : 2 | Train Loss: 0.5056 | Validation Loss: 0.5093\n",
      "Epoch : 3 | Train Loss: 0.5343 | Validation Loss: 0.4938\n",
      "Epoch : 4 | Train Loss: 0.3909 | Validation Loss: 0.4835\n",
      "Epoch : 5 | Train Loss: 0.3996 | Validation Loss: 0.4772\n",
      "Epoch : 6 | Train Loss: 0.4854 | Validation Loss: 0.4735\n",
      "Epoch : 7 | Train Loss: 0.3122 | Validation Loss: 0.4712\n",
      "Epoch : 8 | Train Loss: 0.4243 | Validation Loss: 0.4686\n",
      "Epoch : 9 | Train Loss: 0.7317 | Validation Loss: 0.4670\n",
      "Epoch : 10 | Train Loss: 0.4804 | Validation Loss: 0.4669\n",
      "Epoch : 11 | Train Loss: 0.3504 | Validation Loss: 0.4640\n",
      "Epoch : 12 | Train Loss: 0.5818 | Validation Loss: 0.4646\n",
      "Epoch : 13 | Train Loss: 0.5941 | Validation Loss: 0.4648\n",
      "Epoch : 14 | Train Loss: 0.5646 | Validation Loss: 0.4637\n",
      "Epoch : 15 | Train Loss: 0.4289 | Validation Loss: 0.4634\n",
      "Epoch : 16 | Train Loss: 0.4468 | Validation Loss: 0.4631\n",
      "Epoch : 17 | Train Loss: 0.6355 | Validation Loss: 0.4624\n",
      "Epoch : 18 | Train Loss: 0.4836 | Validation Loss: 0.4629\n",
      "Epoch : 19 | Train Loss: 0.5636 | Validation Loss: 0.4630\n"
     ]
    }
   ],
   "source": [
    "learn = model_learner()\n",
    "learn.fit(model, trainset, validset, 1e-3, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the model\n",
    "* Area Under the ROC is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = valid.df\n",
    "X_valid, y_valid = valid_data.drop('target', axis=1), valid_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = torch.tensor(X_valid.values, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    preds = model(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806234265552601"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_predicted_cls = preds.round().view(-1)\n",
    "roc_auc_score(y_valid, y_predicted_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
